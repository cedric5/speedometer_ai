"""
Streamlit web UI for Speedometer AI
"""

import streamlit as st
import streamlit.components.v1
import os
import tempfile
import pandas as pd
import json
from pathlib import Path
import plotly.express as px
import plotly.graph_objects as go
from speedometer_ai.core import SpeedometerAnalyzer, QuotaExceededError
from speedometer_ai.utils import (
    extract_frames_from_video, 
    save_results_to_csv, 
    validate_video_file,
    check_ffmpeg_available,
    apply_video_crop,
    apply_opencv_speedometer_tracking
)



def load_secrets():
    """Load API keys from secrets.json file"""
    secrets_file = Path(__file__).parent.parent / "secrets.json"
    if secrets_file.exists():
        try:
            with open(secrets_file, 'r') as f:
                return json.load(f)
        except Exception as e:
            st.error(f"Error loading secrets.json: {e}")
            return {}
    return {}


def get_api_key_from_sources():
    """Get API key from secrets file, environment variable, or session state"""
    # First try secrets file
    secrets = load_secrets()
    if secrets.get('gemini_api_key'):
        return secrets['gemini_api_key']
    
    # Then try environment variable
    env_key = os.getenv('GEMINI_API_KEY', '')
    if env_key:
        return env_key
    
    # Finally try session state
    return st.session_state.get('persistent_api_key', '')


def render_upload_section(api_key, fps, delay, model, parallel_workers, anomaly_detection, max_acceleration, interpolate_gaps, keep_frames, verbose):
    """Render the upload section with all upload and cropping functionality"""
    
    has_results = 'analysis_results' in st.session_state
    
    if has_results:
        # Show compact summary when in expander
        results_data = st.session_state.analysis_results
        if results_data:
            video_name = results_data.get('video_name', 'Unknown')
            st.caption(f"‚úÖ Analyzed: {video_name}")
        else:
            st.caption("No analysis results available")
    
    uploaded_file = st.file_uploader(
        "Choose a dashboard video file",
        type=['mp4', 'avi', 'mov', 'mkv'],
        help="Upload a video showing your car's dashboard",
        key="video_upload"
    )
    
    if uploaded_file is not None:
        # Check if this is a new video file and reset state if needed
        if 'current_video_name' not in st.session_state or st.session_state.current_video_name != uploaded_file.name:
            # Reset all session state when new video is uploaded
            st.session_state.current_video_name = uploaded_file.name
            st.session_state.processed_video_path = None
            st.session_state.analysis_results = None
            st.session_state.processing_complete = False
            st.session_state.analysis_complete = False
            # Reset crop values to defaults
            if 'crop_width' in st.session_state:
                del st.session_state.crop_width
            if 'crop_height' in st.session_state:
                del st.session_state.crop_height
            if 'crop_x_pos' in st.session_state:
                del st.session_state.crop_x_pos
            if 'crop_y_pos' in st.session_state:
                del st.session_state.crop_y_pos
            
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
            tmp_file.write(uploaded_file.read())
            temp_video_path = Path(tmp_file.name)
        
        st.success(f"‚úÖ Video uploaded: {uploaded_file.name}")
        
        # Two-column layout for cropping controls and preview
        crop_col1, crop_col2 = st.columns([1, 1])
        
        with crop_col1:
            # Add video processing functionality
            st.subheader("üéØ Video Processing (Optional)")
            st.caption("Process the video to focus on the speedometer area for better accuracy and faster processing")
            
            processing_mode = st.selectbox(
                "Processing Mode",
                ["None", "Basic Crop", "Ultra Tracking"],
                index=0,
                help="‚Ä¢ None: Use original video\n‚Ä¢ Basic Crop: Static crop to speedometer area\n‚Ä¢ Ultra Tracking: Smart tracking that follows the speedometer area"
            )
            
            if processing_mode == "Ultra Tracking":
                st.info(f"‚ÑπÔ∏è **Smart Processing**: Will only process frames at {fps} FPS (same rate as AI analysis) for maximum efficiency")
            
            crop_video = processing_mode != "None"
            
            if crop_video:
                # Get video dimensions for cropping interface
                try:
                    import cv2
                    cap = cv2.VideoCapture(str(temp_video_path))
                    ret, frame = cap.read()
                    if ret:
                        original_height, original_width = frame.shape[:2]
                        cap.release()
                        
                        st.info(f"üìê Original video dimensions: {original_width} x {original_height} pixels")
                        
                        st.markdown("**Crop Area Selection**")
                        
                        # Initialize crop values in session state if not already set
                        if 'crop_width' not in st.session_state:
                            st.session_state.crop_width = min(400, original_width // 2)
                        if 'crop_height' not in st.session_state:
                            st.session_state.crop_height = min(300, original_height // 2)
                        if 'crop_x_pos' not in st.session_state:
                            st.session_state.crop_x_pos = original_width // 4
                        if 'crop_y_pos' not in st.session_state:
                            st.session_state.crop_y_pos = original_height // 4
                        
                        # Crop box size controls
                        st.markdown("**üìè Crop Box Size**")
                        
                        # Width and height sliders for smooth, instant updates
                        crop_width = st.slider(
                            "Width",
                            min_value=50,
                            max_value=original_width,
                            help="Width of the crop area",
                            key="crop_width"
                        )
                        
                        crop_height = st.slider(
                            "Height",
                            min_value=50, 
                            max_value=original_height,
                            help="Height of the crop area",
                            key="crop_height"
                        )
                        
                        # Crop box position controls
                        st.markdown("**üìç Crop Box Position**")
                        
                        # Calculate safe max positions
                        max_x_pos = max(0, original_width - crop_width)
                        max_y_pos = max(0, original_height - crop_height)
                        
                        # Constrain current position values to valid ranges
                        current_x = min(st.session_state.get('crop_x_pos', original_width // 4), max_x_pos)
                        current_y = min(st.session_state.get('crop_y_pos', original_height // 4), max_y_pos)
                        
                        crop_x_pos = st.slider(
                            "Horizontal Position",
                            min_value=0,
                            max_value=max_x_pos,
                            value=current_x,
                            help="Move crop box left/right",
                            key="crop_x_pos"
                        )
                        
                        crop_y_pos = st.slider(
                            "Vertical Position",
                            min_value=0,
                            max_value=max_y_pos,
                            value=current_y,
                            help="Move crop box up/down",
                            key="crop_y_pos"
                        )
                        
                        # Calculate coordinates for compatibility with existing code
                        crop_x1 = crop_x_pos
                        crop_y1 = crop_y_pos
                        crop_x2 = crop_x_pos + crop_width
                        crop_y2 = crop_y_pos + crop_height
                        
                        st.success(f"üéØ Crop area: {crop_width} x {crop_height} pixels at position ({crop_x1}, {crop_y1})")
                        
                        # Apply processing based on selected mode
                        button_text = {
                            "Basic Crop": "‚úÇÔ∏è Apply Basic Crop",
                            "Ultra Tracking": "üöÄ Apply Ultra Tracking"
                        }.get(processing_mode, "‚úÇÔ∏è Apply Processing")
                        
                        if st.button(button_text, type="primary"):
                            # Create progress indicators
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            
                            def progress_callback(progress: float, message: str):
                                progress_bar.progress(progress)
                                status_text.text(message)
                            
                            try:
                                if processing_mode == "Basic Crop":
                                    progress_callback(0.1, "‚úÇÔ∏è Preparing video crop...")
                                    processed_video_path = apply_video_crop(
                                        temp_video_path, 
                                        crop_x1, crop_y1, crop_x2, crop_y2,
                                        progress_callback=progress_callback
                                    )
                                    success_msg = f"‚úÖ Video cropped successfully! New dimensions: {crop_width} x {crop_height}"
                                        
                                elif processing_mode == "Ultra Tracking":
                                    progress_callback(0.05, f"üéØ Preparing OpenCV tracking at {fps} FPS...")
                                    processed_video_path = apply_opencv_speedometer_tracking(
                                        temp_video_path,
                                        crop_x1, crop_y1, crop_x2, crop_y2,
                                        output_width=800, output_height=600,
                                        fps=fps,
                                        progress_callback=progress_callback
                                    )
                                    success_msg = f"‚úÖ OpenCV tracking complete at {fps} FPS! Speedometer tracked and centered: 800x600"
                            
                                if processed_video_path:
                                    temp_video_path = processed_video_path  # Use processed video for analysis
                                    st.success(success_msg)
                                    
                                    # Store processing info and video path in session state
                                    st.session_state.processing_complete = True
                                    st.session_state.processed_video_path = str(processed_video_path)
                                    st.session_state.processing_mode = processing_mode
                                    st.session_state.crop_info = {
                                        'original_size': (original_width, original_height),
                                        'crop_area': (crop_x1, crop_y1, crop_x2, crop_y2),
                                        'processing_mode': processing_mode,
                                        'processed_size': (800, 600) if processing_mode != "Basic Crop" else (crop_width, crop_height)
                                    }
                                    
                                    # Clean up progress indicators
                                    progress_bar.empty()
                                    status_text.empty()
                                    
                                    st.rerun()  # Refresh to show processed video in preview
                                else:
                                    progress_bar.empty()
                                    status_text.empty()
                                    st.error(f"‚ùå Failed to process video with {processing_mode}")
                                    
                            except Exception as e:
                                progress_bar.empty()
                                status_text.empty()
                                st.error(f"‚ùå Error during {processing_mode}: {str(e)}")
                    else:
                        st.error("‚ùå Could not read video for cropping")
                        cap.release()
                except Exception as e:
                    st.error(f"‚ùå Error setting up video cropping: {str(e)}")
        
        with crop_col2:
            if crop_video:
                mode_titles = {
                    "Basic Crop": "**Crop Area Visualization**",
                    "Advanced Stabilization": "**Tracking Area for Stabilization**", 
                    "Ultra Tracking": "**Area to Track & Keep Centered**"
                }
                st.markdown(mode_titles.get(processing_mode, "**Processing Area**"))
                
                # Show crop rectangle on original frame
                try:
                    import cv2
                    cap = cv2.VideoCapture(str(temp_video_path))
                    ret, frame = cap.read()
                    if ret:
                        # Draw rectangle on the frame with color coding
                        preview_frame = frame.copy()
                        color = {
                            "Basic Crop": (0, 255, 0),      # Green for basic crop
                            "Advanced Stabilization": (255, 0, 0),  # Blue for stabilization  
                            "Ultra Tracking": (0, 0, 255)    # Red for ultra tracking
                        }.get(processing_mode, (0, 255, 0))
                        
                        cv2.rectangle(preview_frame, (crop_x1, crop_y1), (crop_x2, crop_y2), color, 3)
                        
                        # Save preview image
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_preview:
                            cv2.imwrite(tmp_preview.name, preview_frame)
                            
                            caption_text = {
                                "Basic Crop": "Green rectangle shows crop area",
                                "Advanced Stabilization": "Blue rectangle shows area to stabilize and center",
                                "Ultra Tracking": "Red rectangle shows area for ultra tracking"
                            }.get(processing_mode, "Rectangle shows processing area")
                            
                            st.image(tmp_preview.name, caption=caption_text, use_container_width=True)
                        
                    cap.release()
                except:
                    pass
            else:
                st.info("üìù Select a processing mode to see area visualization")
        
        # Video preview section
        st.markdown("---")
        
        # Create two columns for video preview and crop preview side by side
        video_col1, video_col2 = st.columns([1, 1])
        
        with video_col1:
            st.subheader("üìπ Video Preview")
            # Show processed video if available, otherwise show original
            if st.session_state.get('processing_complete', False) and 'processed_video_path' in st.session_state:
                processing_mode = st.session_state.get('processing_mode', 'Basic Crop')
                mode_captions = {
                    'Basic Crop': 'üé¨ Showing cropped video',
                    'Ultra Tracking': 'üöÄ Showing tracked video'
                }
                st.caption(mode_captions.get(processing_mode, 'üé¨ Showing processed video'))
                with open(st.session_state.processed_video_path, 'rb') as video_file:
                    st.video(video_file.read(), start_time=0)
            else:
                st.caption("üé¨ Showing original video")
                st.video(uploaded_file, start_time=0)
        
        with video_col2:
            if crop_video and 'original_width' in locals():
                preview_titles = {
                    "Basic Crop": "üñºÔ∏è Live Crop Preview",
                    "Advanced Stabilization": "üéØ Live Tracking Preview", 
                    "Ultra Tracking": "üöÄ Live Tracking Preview"
                }
                st.subheader(preview_titles.get(processing_mode, "üñºÔ∏è Live Preview"))
                
                try:
                    import cv2
                    cap = cv2.VideoCapture(str(temp_video_path))
                    ret, frame = cap.read()
                    if ret:
                        # Show selected area at larger size
                        cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_cropped:
                            cv2.imwrite(tmp_cropped.name, cropped_frame)
                            
                            preview_captions = {
                                "Basic Crop": "This exact area will be in the output video",
                                "Advanced Stabilization": "This area will be tracked and kept centered",
                                "Ultra Tracking": "This area will be perfectly stabilized and tracked"
                            }
                            caption = preview_captions.get(processing_mode, "This area will be processed")
                            
                            st.image(tmp_cropped.name, caption=caption, use_container_width=True)
                    cap.release()
                except:
                    pass
            else:
                st.info("Select a processing mode to see live preview here")
            
        # Add JavaScript to enable video time control
        st.components.v1.html("""
        <script>
        // Function to jump video to specific timestamp
        function jumpVideoToTime(timestamp) {
            // Find the video element in Streamlit
            const videos = document.querySelectorAll('video');
            if (videos.length > 0) {
                const video = videos[0]; // Get the first (main) video element
                if (video) {
                    video.currentTime = timestamp;
                    console.log('Video jumped to:', timestamp, 'seconds');
                    
                    // Optional: Show visual feedback
                    video.style.border = '3px solid #ff4444';
                    setTimeout(() => {
                        video.style.border = 'none';
                    }, 1000);
                }
            } else {
                console.log('No video element found');
            }
        }
        
        // Make function globally available
        window.jumpVideoToTime = jumpVideoToTime;
        
        // Also provide alternative names for compatibility
        window.jumpToTime = jumpVideoToTime;
        
        console.log('Video control functions loaded');
        </script>
        """, height=0)
        
        # Validation
        if not validate_video_file(temp_video_path):
            st.error("‚ùå Invalid video file")
            return
        
        if not check_ffmpeg_available():
            st.error("‚ùå FFmpeg not found. Please install FFmpeg.")
            return
        
        if not api_key:
            st.error("‚ùå Please enter your Gemini API key in the sidebar")
            return
        
        # Cost estimation
        if uploaded_file is not None:
            # Estimate video duration and frames using appropriate video source
            try:
                import cv2
                video_for_estimation = Path(st.session_state.processed_video_path) if st.session_state.get('processing_complete', False) and 'processed_video_path' in st.session_state else temp_video_path
                cap = cv2.VideoCapture(str(video_for_estimation))
                frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
                video_fps = cap.get(cv2.CAP_PROP_FPS)
                duration = frame_count / video_fps if video_fps > 0 else 0
                cap.release()
                
                estimated_frames = int(duration * fps)
                # Use model-specific cost estimation
                cost_estimate = SpeedometerAnalyzer.estimate_cost(
                    estimated_frames, model, include_ai_analysis=False
                )
                
                cost_info = f"üìä **Estimated Analysis**: {estimated_frames} frames (~{duration:.1f}s video) | **Est. Cost**: ${cost_estimate['total_cost_usd']:.4f} USD ({model})"
                if anomaly_detection or interpolate_gaps:
                    cost_info += " | Plus rule-based post-processing (no additional cost)"
                st.info(cost_info)
            except:
                st.warning("‚ö†Ô∏è Could not estimate video duration")
        
        # Analysis button
        if st.button("üîç Analyze Video", type="primary", use_container_width=True):
            # Use cropped video for analysis if available
            video_to_analyze = Path(st.session_state.processed_video_path) if st.session_state.get('processing_complete', False) and 'processed_video_path' in st.session_state else temp_video_path
            analyze_video(video_to_analyze, api_key, model, fps, delay, parallel_workers, anomaly_detection, max_acceleration, interpolate_gaps, keep_frames, verbose)


def main():
    st.set_page_config(
        page_title="Speedometer AI",
        page_icon="üöó",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üöó Speedometer AI")
    st.markdown("AI-powered speedometer reading from dashboard video")
    
    # Sidebar for configuration
    with st.sidebar:
        st.header("Configuration")
        
        # API Key input with multiple sources
        # Initialize from multiple sources: secrets file > environment > session state
        if 'persistent_api_key' not in st.session_state:
            st.session_state.persistent_api_key = get_api_key_from_sources()
        
        # API Key input
        api_key = st.text_input(
            "Gemini API Key", 
            type="password",
            value=st.session_state.persistent_api_key,
            help="API key sources (in priority order):\n1. secrets.json file\n2. GEMINI_API_KEY environment variable\n3. Manual input (persists during session)",
            key="gemini_api_key"
        )
        
        # Update session state when API key changes
        if api_key != st.session_state.persistent_api_key:
            st.session_state.persistent_api_key = api_key
        
        # Show status about API key storage with source info
        secrets = load_secrets()
        env_key = os.getenv('GEMINI_API_KEY', '')
        
        if api_key:
            if secrets.get('gemini_api_key') and api_key == secrets['gemini_api_key']:
                st.success("üîë API key loaded from secrets.json")
            elif env_key and api_key == env_key:
                st.success("üîë API key loaded from environment variable")
            else:
                st.success("üîë API key set manually (persists during session)")
        else:
            st.info("üí° API key sources:\n‚Ä¢ Create secrets.json file (recommended)\n‚Ä¢ Set GEMINI_API_KEY environment variable\n‚Ä¢ Enter manually above")
        
        # Analysis settings
        st.subheader("Analysis Settings")
        fps = st.slider("Frames per second", 1.0, 10.0, 3.0, 0.5)
        delay = st.slider("API delay (seconds)", 0.5, 3.0, 1.0, 0.1)
        
        # Advanced options
        with st.expander("Advanced Options"):
            st.subheader("AI Model")
            model = st.selectbox("Gemini Model", 
                               ["gemini-1.5-flash", "gemini-1.5-pro", "gemini-2.0-flash-exp"],
                               index=0,
                               help="Choose the Gemini model:\n‚Ä¢ Flash: Fastest & cheapest ($0.075/$0.30 per 1M tokens)\n‚Ä¢ Pro: Most accurate but expensive ($1.25/$5.00 per 1M tokens)\n‚Ä¢ 2.0 Experimental: Latest features, FREE during experimental period but very low quota limits")
            
            parallel_workers = st.slider("Parallel workers", 1, 20, 3, 1, 
                                        help="Number of parallel API calls (higher = faster but more load)")
            
            st.subheader("Rule-Based Data Processing")
            anomaly_detection = st.checkbox("Anomaly detection & correction", True,
                                           help="Use rule-based algorithms to detect and correct speed misreadings (e.g., OCR digit confusion)")
            max_acceleration = st.slider("Max car acceleration (km/h/s)", 5.0, 30.0, 16.95, 0.05,
                                       help="Maximum realistic acceleration for your car - used for physics validation")
            interpolate_gaps = st.checkbox("Gap filling & smoothing", True,
                                         help="Use rule-based interpolation and smoothing to fill missing readings and ensure smooth speed lines")
            
            st.subheader("Output Options")
            keep_frames = st.checkbox("Keep extracted frames", False)
            verbose = st.checkbox("Verbose output", False)
            
    
    # Main content area - upload section (collapsible when results are ready)
    has_results = 'analysis_results' in st.session_state
    
    # Show upload section in an expander if results exist, otherwise show normally
    if has_results:
        with st.expander("üìπ Video Upload & Configuration", expanded=False):
            render_upload_section(api_key, fps, delay, model, parallel_workers, anomaly_detection, max_acceleration, interpolate_gaps, keep_frames, verbose)
    else:
        st.header("üìπ Video Upload")
        render_upload_section(api_key, fps, delay, model, parallel_workers, anomaly_detection, max_acceleration, interpolate_gaps, keep_frames, verbose)

    # Show new analysis option when results are available
    if has_results:
        st.markdown("---")
        if st.button("üîÑ Start New Analysis", type="secondary", use_container_width=True):
            # Clear results to show upload section again
            if 'analysis_results' in st.session_state:
                del st.session_state.analysis_results
            st.rerun()

    # Results section
    st.markdown("---")
    st.header("üìä Results")
    
    # Check for existing results
    if 'analysis_results' in st.session_state and st.session_state.analysis_results is not None:
        display_results(st.session_state.analysis_results)
    else:
        st.info("Upload a video and click 'Analyze Video' to see results here")


def analyze_video(video_path: Path, api_key: str, model: str, fps: float, delay: float, parallel_workers: int, anomaly_detection: bool, max_acceleration: float, interpolate_gaps: bool, keep_frames: bool, verbose: bool):
    """Analyze the uploaded video"""
    
    # Create progress indicators
    progress_bar = st.progress(0)
    status_text = st.empty()
    cost_display = st.empty()
    
    try:
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_dir_path = Path(temp_dir)
            frames_dir = temp_dir_path / "frames"
            
            # Step 1: Extract frames
            status_text.text("üìπ Extracting frames from video...")
            progress_bar.progress(0.1)
            
            frame_files = extract_frames_from_video(video_path, frames_dir, fps)
            st.success(f"‚úÖ Extracted {len(frame_files)} frames")
            
            # Step 2: Initialize analyzer
            status_text.text(f"ü§ñ Initializing Gemini AI analyzer ({model})...")
            progress_bar.progress(0.2)
            
            analyzer = SpeedometerAnalyzer(api_key, model_name=model)
            
            # Step 3: Analyze frames
            if parallel_workers > 1:
                status_text.text(f"üîç Analyzing frames with {parallel_workers} parallel workers...")
            else:
                status_text.text("üîç Analyzing frames with AI...")
            
            def progress_callback(current, total, filename):
                progress = 0.2 + (current / total) * 0.6
                progress_bar.progress(progress)
                
                # Get current cost info and update displays
                cost_info = analyzer.get_cost_info()
                cost_str = f"${cost_info['total_cost_usd']:.4f}" if cost_info['total_cost_usd'] > 0 else "<$0.0001"
                
                if parallel_workers > 1:
                    status_text.text(f"üîç Completed {current}/{total}: {filename}")
                else:
                    status_text.text(f"üîç Analyzing frame {current}/{total}: {filename}")
                
                # Update cost display in real-time
                cost_display.info(f"üí∞ **Real-time Cost**: {cost_str} USD | **API Calls**: {cost_info['api_calls']} | **Model**: {cost_info['model']}")
            
            try:
                results = analyzer.analyze_video_frames(
                    frames_dir, fps, delay, progress_callback, max_workers=parallel_workers
                )
            except QuotaExceededError as e:
                st.error(f"üö´ **Quota Exceeded**\n\n{str(e)}")
                st.info("üí° **Quick Fix**: Change the model to 'gemini-1.5-flash' and reduce parallel workers to 1-2 in the sidebar settings.")
                return
            except Exception as e:
                error_str = str(e)
                st.error(f"‚ùå **Analysis Failed**: {error_str}")
                
                # Provide specific guidance
                if "429" in error_str or "quota" in error_str.lower():
                    st.warning("üí° **Rate Limit Issue**: Reduce parallel workers and try gemini-1.5-flash model")
                elif "api" in error_str.lower() or "key" in error_str.lower():
                    st.warning("üí° **API Key Issue**: Check your API key is valid and has access to the selected model")
                elif "permission" in error_str.lower():
                    st.warning(f"üí° **Permission Issue**: Your API key may not have access to the {model} model")
                else:
                    st.warning("üí° **Troubleshooting**: Try gemini-1.5-flash model with 1 parallel worker")
                return
            
            # Step 4: Post-process results
            status_text.text("üîß Post-processing results...")
            progress_bar.progress(0.8)
            
            raw_success_rate = len([r for r in results if r['success']]) / len(results) * 100
            
            if anomaly_detection or interpolate_gaps:
                status_text.text("üîß Rule-based analyzing speed data for anomalies and gaps...")
                try:
                    results = analyzer.analyze_speed_data_with_rules(results, max_acceleration)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Rule-based analysis failed: {e}")
                    # Manual fallback if the integrated method fails
                    if anomaly_detection:
                        status_text.text("üîß Detecting and correcting anomalies...")
                        from .utils import detect_and_correct_anomalies
                        results = detect_and_correct_anomalies(results, max_change_per_second=max_acceleration)
                    
                    if interpolate_gaps:
                        status_text.text("üîß Filling gaps using interpolation...")
                        from .utils import interpolate_missing_speeds
                        results = interpolate_missing_speeds(results, max_gap_size=3)
            
            # Show improvement if processing was applied
            if anomaly_detection or interpolate_gaps:
                processed_success_rate = len([r for r in results if r['success']]) / len(results) * 100
                corrected_count = len([r for r in results if r.get('anomaly_corrected', False)])
                interpolated_count = len([r for r in results if r.get('interpolated', False)])
                smoothed_count = len([r for r in results if r.get('smoothed', False)])
                
                if processed_success_rate > raw_success_rate:
                    improvement = processed_success_rate - raw_success_rate
                    st.info(f"‚ú® Rule-based processing improved success rate by {improvement:.1f}% ({raw_success_rate:.1f}% ‚Üí {processed_success_rate:.1f}%)")
                
                if corrected_count > 0:
                    st.success(f"‚ö†Ô∏è Corrected {corrected_count} anomalous readings")
                if interpolated_count > 0:
                    st.success(f"üîÆ Interpolated {interpolated_count} missing values")
                if smoothed_count > 0:
                    st.success(f"üìà Smoothed {smoothed_count} outlier readings")
            
            # Step 5: Finalize results
            status_text.text("üìä Finalizing results...")
            progress_bar.progress(0.9)
            
            # Store results in session state
            st.session_state.analysis_results = {
                'results': results,
                'stats': analyzer.get_statistics(),
                'cost_info': analyzer.get_cost_info(),
                'video_name': video_path.name,
                'video_path': str(video_path)
            }
            
            progress_bar.progress(1.0)
            status_text.text("‚úÖ Analysis complete!")
            
            # Final cost display
            final_cost_info = analyzer.get_cost_info()
            final_cost_str = f"${final_cost_info['total_cost_usd']:.4f}" if final_cost_info['total_cost_usd'] > 0 else "<$0.0001"
            cost_display.success(f"üí∞ **Final Cost**: {final_cost_str} USD | **Total API Calls**: {final_cost_info['api_calls']}")
            
            st.success("üéâ Analysis completed successfully!")
            st.rerun()
            
    except Exception as e:
        st.error(f"‚ùå Error during analysis: {str(e)}")
        progress_bar.empty()
        status_text.empty()
        cost_display.empty()


def display_results(analysis_data):
    """Display analysis results"""
    
    results = analysis_data['results']
    stats = analysis_data['stats']
    cost_info = analysis_data.get('cost_info', {})
    video_name = analysis_data['video_name']
    video_path = analysis_data.get('video_path', None)
    
    # Summary metrics - displayed in a simple grid without nested columns
    st.subheader("üìä Summary Statistics")
    
    # Create metrics in rows instead of columns to avoid nesting issues
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Total Frames", stats.get('total_frames', 0))
    
    with col2:
        st.metric("Duration", f"{stats.get('duration', 0):.1f}s")
    
    with col3:
        if 'min_speed' in stats:
            st.metric("Speed Range", f"{stats['min_speed']}-{stats['max_speed']} km/h")
        else:
            st.metric("Speed Range", "N/A")
    
    with col4:
        success_rate = stats.get('success_rate', 0)
        # Calculate breakdown
        ai_readings = len([r for r in results if r['success'] and not r.get('interpolated', False) and not r.get('anomaly_corrected', False)])
        interpolated_count = len([r for r in results if r.get('interpolated', False)])
        anomaly_corrected_count = len([r for r in results if r.get('anomaly_corrected', False)])
        
        st.metric("Success Rate", f"{success_rate:.1f}%", 
                 help=f"AI: {ai_readings}, Anomaly Corrected: {anomaly_corrected_count}, Interpolated: {interpolated_count}")
    
    # Cost information in a separate row
    if cost_info.get('total_cost_usd', 0) > 0:
        st.metric("Analysis Cost", f"${cost_info['total_cost_usd']:.4f}")
    
    # Create DataFrame for display
    df = pd.DataFrame(results)
    
    # Speed chart with timestamp selection
    if len(df[df['success'] == True]) > 0:
        st.subheader("üìà Interactive Speed Analysis")
        
        successful_df = df[df['success'] == True].copy()
        
        # Add timestamp selection functionality
        st.markdown("**‚è∞ Video Timestamp Navigation**")
        st.caption("Use the slider below to explore different timestamps. The chart will highlight the selected point with smooth, responsive updates.")
        
        max_time = successful_df['timestamp'].max() if len(successful_df) > 0 else 10.0
        
        # Timestamp selection
        selected_timestamp = st.slider(
            "Select timestamp to view:",
            min_value=0.0,
            max_value=float(max_time),
            value=0.0,
            step=0.01,  # Ultra-fine step for instant, smooth updates
            format="%.2fs",
            help="Drag the slider - graph updates instantly as you move it"
        )
        
        # Show current selection info
        if len(successful_df) > 0:
            closest_idx = (successful_df['timestamp'] - selected_timestamp).abs().idxmin()
            closest_speed = successful_df.loc[closest_idx, 'speed']
            st.info(f"**Selected Time**: {selected_timestamp:.1f}s | **Speed**: {closest_speed:.0f} km/h")
        
        # Video jumping functionality temporarily disabled for performance
        # Will be re-implemented later with a more efficient approach
        
        # Optimized Interactive chart with caching
        # Create base chart only once and cache it
        if 'base_chart_data' not in st.session_state or len(st.session_state.get('base_chart_data', {})) == 0:
            st.session_state.base_chart_data = {
                'timestamps': successful_df['timestamp'].tolist(),
                'speeds': successful_df['speed'].tolist(),
                'max_speed': successful_df['speed'].max(),
                'min_speed': successful_df['speed'].min()
            }
        
        chart_data = st.session_state.base_chart_data
        
        # Find closest point efficiently
        timestamps_array = chart_data['timestamps']
        closest_idx = min(range(len(timestamps_array)), 
                         key=lambda i: abs(timestamps_array[i] - selected_timestamp))
        selected_point_time = timestamps_array[closest_idx]
        selected_point_speed = chart_data['speeds'][closest_idx]
        
        # Create optimized figure with minimal traces
        fig = go.Figure()
        
        # Main speed line (single trace)
        fig.add_trace(go.Scatter(
            x=chart_data['timestamps'],
            y=chart_data['speeds'],
            mode='lines+markers',
            name='Speed',
            line=dict(width=2, color='#1f77b4'),
            marker=dict(size=4),
            hovertemplate='<b>%{x:.1f}s</b>: %{y:.0f} km/h<extra></extra>'
        ))
        
        # Selected point (single marker)
        fig.add_trace(go.Scatter(
            x=[selected_point_time],
            y=[selected_point_speed],
            mode='markers',
            name='Selected',
            marker=dict(size=12, color='red', symbol='circle-open', line=dict(width=2)),
            hovertemplate=f'<b>SELECTED</b><br>{selected_point_time:.1f}s: {selected_point_speed:.0f} km/h<extra></extra>'
        ))
        
        # Optimized layout
        fig.update_layout(
            title=dict(text="Speed Timeline", font=dict(size=16)),
            xaxis=dict(title="Time (s)", range=[0, max_time]),
            yaxis=dict(title="Speed (km/h)", range=[chart_data['min_speed']-5, chart_data['max_speed']+5]),
            hovermode='closest',
            height=350,
            showlegend=False,
            margin=dict(l=50, r=20, t=40, b=40),
            # Performance optimizations
            uirevision='chart_data',  # Prevents zoom reset
            dragmode='pan'  # Faster than zoom for timeline navigation
        )
        
        # Add vertical line as shape (faster than vline)
        fig.add_shape(
            type="line",
            x0=selected_timestamp, x1=selected_timestamp,
            y0=chart_data['min_speed']-5, y1=chart_data['max_speed']+5,
            line=dict(color="red", width=2, dash="dash")
        )
        
        # Render with maximum performance optimizations for instant updates
        st.plotly_chart(
            fig, 
            use_container_width=True, 
            key="speed_chart",
            config={
                'displayModeBar': False,  # Hide toolbar for faster rendering
                'staticPlot': False,
                'responsive': True,
                'doubleClick': False,  # Disable double-click zoom for speed
                'showTips': False,  # Disable tooltips delay
                'displaylogo': False  # Remove plotly logo for cleaner UI
            }
        )
        
        # Show information about the selected timestamp
        if len(successful_df) > 0:
            closest_idx = (successful_df['timestamp'] - selected_timestamp).abs().idxmin()
            selected_data = successful_df.loc[closest_idx]
            
            st.info(
                f"üéØ **Selected Frame**: {selected_data['filename']} | "
                f"**Time**: {selected_data['timestamp']:.1f}s | "
                f"**Speed**: {selected_data['speed']:.0f} km/h"
            )
    
    # Detailed results table
    st.subheader("üìã Detailed Results")
    
    # Add legend
    st.caption("**Status Legend:** ‚úÖ Rule-based Read = Direct reading | ‚ö†Ô∏è Corrected = Misread digit corrected | üîÆ Estimated = Value interpolated from surrounding data | ‚ùå Failed = No reading available")
    
    # Format the dataframe for display
    display_df = df.copy()
    
    def format_status(row):
        if row['success']:
            if row.get('interpolated', False):
                return 'üîÆ Estimated'
            elif row.get('anomaly_corrected', False):
                return '‚ö†Ô∏è Corrected'
            else:
                return '‚úÖ Rule-based Read'
        else:
            return '‚ùå Failed'
    
    display_df['Status'] = display_df.apply(format_status, axis=1)
    display_df['Speed (km/h)'] = display_df['speed'].apply(lambda x: f"{x:.0f}" if pd.notna(x) else "N/A")
    display_df['Time (s)'] = display_df['timestamp'].apply(lambda x: f"{x:.1f}")
    
    st.dataframe(
        display_df[['Status', 'Time (s)', 'Speed (km/h)', 'filename']],
        use_container_width=True,
        hide_index=True
    )
    
    # Cost breakdown section
    if cost_info:
        st.subheader("üí∞ Cost Breakdown")
        
        # Display cost metrics in a simple layout
        st.text(f"Model: {cost_info.get('model', 'N/A')} | API Calls: {cost_info.get('api_calls', 0)}")
        st.text(f"Input Tokens: {cost_info.get('input_tokens', 0):,} | Output Tokens: {cost_info.get('output_tokens', 0):,}")
        st.text(f"Input Cost: ${cost_info.get('input_cost_usd', 0):.6f} | Output Cost: ${cost_info.get('output_cost_usd', 0):.6f}")
        
        if cost_info.get('total_cost_usd', 0) < 0.01:
            st.success("üí° Very affordable! Less than 1 cent.")
        elif cost_info.get('total_cost_usd', 0) < 0.10:
            st.info("üí° Very reasonable cost, less than 10 cents.")
        else:
            st.warning("‚ö†Ô∏è Consider optimizing frames/fps for cost reduction.")
    
    # Download section
    st.subheader("üíæ Download Results")
    
    # CSV download
    csv_data = df.to_csv(index=False)
    st.download_button(
        label="üìÑ Download CSV",
        data=csv_data,
        file_name=f"{Path(video_name).stem}_speed_analysis.csv",
        mime="text/csv"
    )
    
    # Summary report
    report = generate_summary_report(results, stats, video_name, cost_info)
    st.download_button(
        label="üìä Download Report",
        data=report,
        file_name=f"{Path(video_name).stem}_analysis_report.txt",
        mime="text/plain"
    )


def generate_summary_report(results, stats, video_name, cost_info=None):
    """Generate a text summary report"""
    
    report = f"""SPEEDOMETER ANALYSIS REPORT
{'='*50}

Video: {video_name}
Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

SUMMARY STATISTICS:
‚Ä¢ Total frames: {stats.get('total_frames', 0)}
‚Ä¢ Successful readings: {stats.get('successful_readings', 0)}
‚Ä¢ Success rate: {stats.get('success_rate', 0):.1f}%
‚Ä¢ Duration: {stats.get('duration', 0):.1f} seconds
"""
    
    if 'min_speed' in stats:
        report += f"""‚Ä¢ Speed range: {stats['min_speed']}-{stats['max_speed']} km/h
‚Ä¢ Average speed: {stats['avg_speed']:.1f} km/h
"""
    
    if cost_info:
        report += f"""
COST BREAKDOWN:
‚Ä¢ Model: {cost_info.get('model', 'N/A')}
‚Ä¢ API calls: {cost_info.get('api_calls', 0)}
‚Ä¢ Input tokens: {cost_info.get('input_tokens', 0):,}
‚Ä¢ Output tokens: {cost_info.get('output_tokens', 0):,}
‚Ä¢ Total cost: ${cost_info.get('total_cost_usd', 0):.6f} USD
"""
    
    report += f"""
DETAILED TIMELINE:
{'-'*30}
"""
    
    for result in results:
        status = "‚úì" if result['success'] else "‚úó"
        speed_str = f"{result['speed']:3.0f}" if result['speed'] else "N/A"
        report += f"{status} {result['timestamp']:5.1f}s: {speed_str} km/h\n"
    
    report += f"""
{'-'*30}
Generated by Speedometer AI v1.0.0
"""
    
    return report


if __name__ == "__main__":
    main()